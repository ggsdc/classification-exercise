\documentclass[a4paper,11pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[dvipdfmx]{graphicx}
\usepackage{graphics,latexsym}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage[dvips]{color}
\usepackage{subfigure}
\usepackage{verbatim}


\usepackage{graphicx}          % Gráficos 
\usepackage{geometry}
\usepackage{fancyhdr}          % Personalizar estilo página
%\usepackage{fancyheadings}     % Para los headers y footers - Deprecated
\usepackage{color}             % Foreground and background color management
\usepackage[usenames,dvipsnames,table]{xcolor}   % Permite modificar tonos de color de forma sencilla
\usepackage{import}            % Importar ficheros de carpetas dentro de este proyecto
\usepackage{listings}          % Permite pegar texto sin formato. Específico para pegar código
\usepackage{placeins}          % Float barriers para imágenes/tablas/etc
\usepackage{float}             % Usar [H] para tablas
\usepackage{amsmath}           % Fórmulas matemáticas
\usepackage{verbatimbox}       % Encuandrar en cajas texto sin formato (verbatim)
\usepackage{tikz}              % Para graficar desde latex
\usepackage{tikz-qtree}        % Para dibujar esquemas en forma de árbol
\usepackage{soul}              % Para separar con guiones las palabras cuando no caben en la línea de texto
\usepackage{titlesec}          % Select alternative section titles
\usepackage{hyperref}          % Vínculos
\usepackage{nameref}           % Permite poner referencias con nombre en vez de con número.



\bibpunct{(}{)}{;}{a}{,}{,}

\textheight 24cm \textwidth 17cm \topmargin-2cm
%% \evensidemargin   -0.25cm
\oddsidemargin-0.2cm
%\pagestyle{empty}
\renewcommand{\baselinestretch}{1}

\begin{document}

\title{Classification and clustering of clients who will churn with various algorithms}

\author{{Guillermo González-Santander de la Cruz}\\
{\small Computational Intelligence Group, Departamento de Inteligencia Artificial, Universidad Politécnica de Madrid, Spain}}

\date{2020-01-08}
\maketitle

%\title{}

%\address{}

\begin{abstract}
\end{abstract}


\ \\
KEY WORDS: Churn prediction; Classification; Clustering; Cross-valdiation; Grid-search

\section{Introduction}

The aim of this work is to predict which clients of a telecom company are going to churn and which are not. In particular the dataset comes IBM Sample Data Sets.
We will use both classification and clustering to try asses two different things. First, with classification, we will try to build a model that tells us if a customer is going to left the services company based on the training data and available information; second, with clustering, we will try to divide the customers in two groups, which clearly separates the customers that left the company from those that still use the services of the company.
For both task we will use different methods in order to find which gives es the best accuracy along with explainability and speed.
All the algorithms that need hiperparameter tunning have been trinen with ten fold cross-validation.

\section{Preliminaries}

\section{Dataset and analysis}

The dataset used for this work comes from the IBM Sample Data Sets (\url{https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2017/06/19/guide-to-ibm-cognos-analytics-sample-data-sets}), in the website a more recent version of the dataset can be found.

The dataset does not have any missing value and has both numerical an qualitative attributes. The details of the attributes are:

\begin{enumerate}
	\item \textbf{customerID}: Unique ID code for each customer. It will not be used in the analysis.
	\item \textbf{gender}: Qualitative variable if the customer is either female or male. It is fairly balanced (49.52\% female).
	\item \textbf{SeniorCitizen}: Binary variable if the customer is considered a senior citizen. It is not well balanced (16.21\% senior).
	\item \textbf{Partner}: Qualitative variable (yes / no) if the customer has a partner. It is well balanced (45.94\% yes).
	\item \textbf{Dependents}: Qualitative variable (yes / no) if the customer has dependents. It is not well balanced (29,95\% yes).
	\item \textbf{tenure}: Quantitative variable (integer) with the amount of months the customer has been with the company.
	\item \textbf{PhoneService}: Qualitative variable (yes / no) if the customer has phone service with the company.
	\item \textbf{MultipleLines}: Qualitative variable (yes / no / no phone service) if the customer has multiple phone lines.
	\item \textbf{InternetService}: Qualitative variable (DSL / Fiber optic/no) if the customer has internet service with the company.
	\item \textbf{OnlineSecurity}: Qualitative variable (yes / no / no internet service) if the customer has online security with the company.
	\item \textbf{OnlineBackup}: Qualitative variable (yes / no / no internet service) if the customer has online backup with the company.
	\item \textbf{DeviceProtection}: Qualitative variable (yes / no / no internet service) if the customer has device protection with the company.
	\item \textbf{TechSupport}: Qualitative variable (yes / no / no internet service) if the customer has tech support with the company.
	\item \textbf{StreamingTV}: Qualitative variable (yes / no / no internet service) if the customer has streaming tv with the company.
	\item \textbf{StreamingMovies}: Qualitative variable (yes / no / no internet service) if the customer has streaming movies with the company.
	\item \textbf{Contract}: Qualitative variable (Month-to-month / One year / Two year) indicating the type of contratc that the customer has.
	\item \textbf{PaperlessBilling}: Qualitative variable (yes / no) if the customer has paperless billing or not.
	\item \textbf{PaymentMethod}: Qualitative variable (Bank transfer / credit card / electronic check / mailed check) indicating the payment method used by the customer.
	\item \textbf{MonthlyCharges}: Quantitative variable (real) with the amount the customer has to pay everymonth.
	\item \textbf{TotalCharges}: Quantitative variable (real) with the amount the customer has paid during their tenure with the company.
	\item \textbf{Churn}: Qualitative variable (yes / no) if the customer has left the company.
\end{enumerate}

In order to apply the algorithms for classification and clustering two pre-processes are going to be applied: the quantitative variables of $n$ levels are going to be one-hot encoded in $n-1$ variables; and all the variables are going to be scaled to the [0, 1] range.

\section{Methodology}

\subsection{Classification}

We are going to be apply the following algorithms for the classification part of the work: \textit{k-nearest-neighbors} (\textit{knn}, with a similar approach as condensed nearest neighbors algorithm, \cite{hart1968}), classification trees (with the CART algorithm, \cite{breiman1984), a naive bayes classifier (\cite{minsky1961}), logistic regression (), rule induction (), and a series of metaclassifiers: bagging of classification trees (\cite{breiman1996}), random forest (\cite{breiman2001}) and gradient boosting with classification trees (\cite{freund1997}).

For all the algorithms that are going to be used we are going to apply the same methodology

\subsection{Clustering}

\section{Classification algorithms}

\section{Clustering algorithms}

\section{Conclusions and future work}

\section{Acknowledgments}


\bibliographystyle{plainnat}
\begin{thebibliography}{}

\bibitem[Breiman \textit{et al}, 1984]{breiman1984}
Breiman, L., Friedman, J. H., Olshen, R., & Stone, C. J. (1984). \textit{Classification and Regression Trees}.

\bibitem[Breiman, 1996]{breiman1996}
Breiman, L. (1996). Bagging predictors. Machine learning, 24(2), 123-140

\bibitem[Breiman, 2001]{breiman2001}
Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.

\bibitem[Freund and Schapire, 1997]{freund1997}
Freund, Y., & Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1), 119-139

\bibitem[Hart, 1968]{hart1968}
Hart, P. (1968). The condensed nearest neighbor rule (Corresp.). IEEE transactions on information theory, 14(3), 515-516.

\bibitem[Minsky, 1961]{minsky1961}
Minsky, M. (1961). Steps toward artificial intelligence. Proceedings of the IRE, 49(1), 8-30


\end{thebibliography}


\end{document}

